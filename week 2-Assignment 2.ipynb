{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254989"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(moby_tokens)#nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(moby_tokens))#nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "\n",
    "    return example_two()/example_one()\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004125668166077752"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "def answer_two():\n",
    "    \n",
    "    dist=FreqDist(text1)\n",
    "    \n",
    "    return ((dist['whale']+dist['Whale'])/example_one())*100\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def answer_three():\n",
    "    \n",
    "    dist=FreqDist(text1)\n",
    "    dist2=pd.Series(dist)\n",
    "    dist2.sort_values(ascending=False, inplace=True)\n",
    "    dist3=dist2[:20]\n",
    "     \n",
    "    return list(zip(dist3.index, dist3))\n",
    "\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['According',\n",
       " 'Africa',\n",
       " 'Alabama',\n",
       " 'Almost',\n",
       " 'America',\n",
       " 'American',\n",
       " 'Americans',\n",
       " 'Another',\n",
       " 'Atlantic',\n",
       " 'Bachelor',\n",
       " 'Because',\n",
       " 'Bedford',\n",
       " 'Besides',\n",
       " 'Bildad',\n",
       " 'Bulkington',\n",
       " 'Bunger',\n",
       " 'CHAPTER',\n",
       " 'Cabaco',\n",
       " 'Canallers',\n",
       " 'Captain',\n",
       " 'Carpenter',\n",
       " 'Cetology',\n",
       " 'Charity',\n",
       " 'Christian',\n",
       " 'Christians',\n",
       " 'Coffin',\n",
       " 'Commodore',\n",
       " 'Consider',\n",
       " 'Cuvier',\n",
       " 'DUODECIMO',\n",
       " 'Daggoo',\n",
       " 'Delight',\n",
       " 'Derick',\n",
       " 'Dough-Boy',\n",
       " 'During',\n",
       " 'Egyptian',\n",
       " 'Elijah',\n",
       " 'Enderby',\n",
       " 'England',\n",
       " 'English',\n",
       " 'Equator',\n",
       " 'Fast-Fish',\n",
       " 'Father',\n",
       " 'Fedallah',\n",
       " 'Fishery',\n",
       " 'Fleece',\n",
       " 'French',\n",
       " 'Frenchman',\n",
       " 'Gabriel',\n",
       " 'George',\n",
       " 'German',\n",
       " 'Greenland',\n",
       " 'Guernsey-man',\n",
       " 'Halloa',\n",
       " 'Heaven',\n",
       " 'Heidelburgh',\n",
       " 'Hercules',\n",
       " 'However',\n",
       " 'Hurrah',\n",
       " 'Hussey',\n",
       " 'Indeed',\n",
       " 'Indian',\n",
       " 'Instantly',\n",
       " 'Ishmael',\n",
       " 'Japanese',\n",
       " 'Jeroboam',\n",
       " 'King-Post',\n",
       " 'Lakeman',\n",
       " 'Landlord',\n",
       " 'Leviathan',\n",
       " 'Leviathans',\n",
       " 'London',\n",
       " 'Loose-Fish',\n",
       " 'Manxman',\n",
       " 'Mapple',\n",
       " 'Mayhew',\n",
       " 'Meantime',\n",
       " 'Meanwhile',\n",
       " 'Mediterranean',\n",
       " 'Methinks',\n",
       " 'Monsieur',\n",
       " 'Moreover',\n",
       " 'Morning',\n",
       " 'NANTUCKET',\n",
       " 'Nantucket',\n",
       " 'Nantucketer',\n",
       " 'Nantucketers',\n",
       " 'Narwhale',\n",
       " 'Nature',\n",
       " 'Nevertheless',\n",
       " 'Nineveh',\n",
       " 'Nothing',\n",
       " 'OCTAVO',\n",
       " 'Oriental',\n",
       " 'Pacific',\n",
       " 'Parsee',\n",
       " 'Pequod',\n",
       " \"Pequod's\",\n",
       " 'Perhaps',\n",
       " 'Perseus',\n",
       " 'Persian',\n",
       " 'Porpoise',\n",
       " 'Presently',\n",
       " 'Quaker',\n",
       " 'Queequeg',\n",
       " 'Quohog',\n",
       " 'Rachel',\n",
       " 'Radney',\n",
       " 'Ramadan',\n",
       " 'SAILOR',\n",
       " 'SNEEZES',\n",
       " 'Samuel',\n",
       " 'Scoresby',\n",
       " 'Sebastian',\n",
       " 'Seeing',\n",
       " 'Solomon',\n",
       " 'Sometimes',\n",
       " 'Southern',\n",
       " 'Spanish',\n",
       " 'Spring',\n",
       " 'Standing',\n",
       " 'Starbuck',\n",
       " 'Steelkilt',\n",
       " 'Sumatra',\n",
       " 'Sunday',\n",
       " 'Tahiti',\n",
       " 'Tarshish',\n",
       " 'Tashtego',\n",
       " 'Temple',\n",
       " 'Therefore',\n",
       " 'Though',\n",
       " 'Through',\n",
       " 'Thunder',\n",
       " 'Towards',\n",
       " 'Town-Ho',\n",
       " 'Typhoon',\n",
       " 'VOYAGE',\n",
       " 'Vineyard',\n",
       " 'Vishnoo',\n",
       " 'WHALING',\n",
       " 'Whales',\n",
       " 'Whaling',\n",
       " 'Wherefore',\n",
       " 'Whether',\n",
       " 'Yarman',\n",
       " 'Zealand',\n",
       " 'abandoned',\n",
       " 'aboard',\n",
       " 'abounding',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'accident',\n",
       " 'accidents',\n",
       " 'accompanied',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounted',\n",
       " 'accounts',\n",
       " 'accursed',\n",
       " 'across',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'additional',\n",
       " 'addressed',\n",
       " 'adequately',\n",
       " 'adrift',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advice',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'against',\n",
       " 'alarmed',\n",
       " 'albatross',\n",
       " 'allowed',\n",
       " 'alluded',\n",
       " 'allusions',\n",
       " 'almost',\n",
       " 'alongside',\n",
       " 'already',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'ambergris',\n",
       " 'amount',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'angels',\n",
       " 'anguish',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anything',\n",
       " 'anywhere',\n",
       " 'apartment',\n",
       " 'appalling',\n",
       " 'apparently',\n",
       " 'apparition',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'applied',\n",
       " 'approaching',\n",
       " 'archangel',\n",
       " 'arched',\n",
       " 'argument',\n",
       " 'around',\n",
       " 'arrived',\n",
       " 'articles',\n",
       " 'ascending',\n",
       " 'ashore',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'assured',\n",
       " 'astern',\n",
       " 'astonishment',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audacious',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'awaiting',\n",
       " 'awhile',\n",
       " 'backward',\n",
       " 'baleen',\n",
       " 'barbaric',\n",
       " 'barbed',\n",
       " 'barrels',\n",
       " 'battle',\n",
       " 'bearing',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'beheaded',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'beholding',\n",
       " 'beings',\n",
       " 'believe',\n",
       " 'bellies',\n",
       " 'belong',\n",
       " 'belonged',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'beneath',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'bestowed',\n",
       " 'bethink',\n",
       " 'betrayed',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bidding',\n",
       " 'billows',\n",
       " 'binnacle',\n",
       " 'biscuit',\n",
       " 'bitter',\n",
       " 'blackness',\n",
       " 'blacksmith',\n",
       " 'blades',\n",
       " 'blanket',\n",
       " 'blasted',\n",
       " 'blazing',\n",
       " 'blessed',\n",
       " 'blindly',\n",
       " 'blinds',\n",
       " 'blocks',\n",
       " 'bloody',\n",
       " 'blowing',\n",
       " 'blubber',\n",
       " 'boarded',\n",
       " 'bodies',\n",
       " 'bodily',\n",
       " 'boiling',\n",
       " 'boldly',\n",
       " 'bolted',\n",
       " 'bottom',\n",
       " 'bottomless',\n",
       " 'boundless',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'bowsman',\n",
       " 'bowsprit',\n",
       " 'braces',\n",
       " 'brains',\n",
       " 'brawny',\n",
       " 'breadth',\n",
       " 'breakers',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathes',\n",
       " 'breathing',\n",
       " 'breaths',\n",
       " 'breeze',\n",
       " 'bright',\n",
       " 'bringing',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'bubble',\n",
       " 'bubbles',\n",
       " 'bucket',\n",
       " 'buffalo',\n",
       " 'bulwarks',\n",
       " 'buoyant',\n",
       " 'burden',\n",
       " 'buried',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'bursting',\n",
       " 'business',\n",
       " 'butter',\n",
       " 'calculated',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calmly',\n",
       " \"can'st\",\n",
       " 'candle',\n",
       " 'candles',\n",
       " 'cannibal',\n",
       " 'cannibals',\n",
       " 'canoes',\n",
       " 'canvas',\n",
       " 'capable',\n",
       " 'capstan',\n",
       " 'captain',\n",
       " 'captains',\n",
       " 'capture',\n",
       " 'captured',\n",
       " 'carcase',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'carpenter',\n",
       " 'carried',\n",
       " 'carries',\n",
       " 'carrying',\n",
       " 'carved',\n",
       " 'casting',\n",
       " 'catching',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'caused',\n",
       " 'ceiling',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'centuries',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chains',\n",
       " 'chance',\n",
       " 'chanced',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'chapel',\n",
       " 'chapter',\n",
       " 'chapters',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charts',\n",
       " 'chased',\n",
       " 'chasing',\n",
       " 'cheeks',\n",
       " 'cheese',\n",
       " 'cherish',\n",
       " 'chiefly',\n",
       " 'children',\n",
       " 'chimney',\n",
       " 'chocks',\n",
       " 'church',\n",
       " 'churches',\n",
       " 'churning',\n",
       " 'circle',\n",
       " 'circles',\n",
       " 'circumference',\n",
       " 'circumstance',\n",
       " 'circumstances',\n",
       " 'civilized',\n",
       " 'clinging',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'clouds',\n",
       " 'clumsy',\n",
       " 'coasts',\n",
       " 'coffin',\n",
       " 'coiled',\n",
       " 'coiling',\n",
       " 'colossal',\n",
       " 'colour',\n",
       " 'combined',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'command',\n",
       " 'commanded',\n",
       " 'commander',\n",
       " 'commenced',\n",
       " 'commerce',\n",
       " 'common',\n",
       " 'commonly',\n",
       " 'commotion',\n",
       " 'company',\n",
       " 'comparative',\n",
       " 'comparatively',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparison',\n",
       " 'compass',\n",
       " 'compasses',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complexion',\n",
       " 'comrade',\n",
       " 'comrades',\n",
       " 'conceit',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concerning',\n",
       " 'conclude',\n",
       " 'concluded',\n",
       " 'concluding',\n",
       " 'conclusion',\n",
       " 'condition',\n",
       " 'conduct',\n",
       " 'confess',\n",
       " 'confidence',\n",
       " 'confidential',\n",
       " 'congregation',\n",
       " 'connected',\n",
       " 'connexion',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'conscious',\n",
       " 'consciousness',\n",
       " 'consequence',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'considerably',\n",
       " 'consideration',\n",
       " 'considerations',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'conspicuous',\n",
       " 'consternation',\n",
       " 'contact',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'contents',\n",
       " 'continual',\n",
       " 'continually',\n",
       " 'continued',\n",
       " 'contrary',\n",
       " 'contrast',\n",
       " 'contrasting',\n",
       " 'contrivances',\n",
       " 'convenient',\n",
       " 'cooked',\n",
       " 'coolly',\n",
       " 'copper',\n",
       " 'corner',\n",
       " 'corpse',\n",
       " 'corpusants',\n",
       " 'correct',\n",
       " 'corresponding',\n",
       " 'countenance',\n",
       " 'counterpane',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'courses',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'coward',\n",
       " 'cracked',\n",
       " 'crawling',\n",
       " 'creation',\n",
       " 'creature',\n",
       " 'creatures',\n",
       " 'critical',\n",
       " 'crooked',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crotch',\n",
       " 'cruise',\n",
       " 'cruising',\n",
       " 'crushed',\n",
       " 'cunning',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'curiously',\n",
       " 'curled',\n",
       " 'curling',\n",
       " 'currents',\n",
       " 'cursed',\n",
       " 'custom',\n",
       " 'customary',\n",
       " 'cutting',\n",
       " 'cutting-spade',\n",
       " 'damned',\n",
       " 'dancing',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'daring',\n",
       " 'darker',\n",
       " 'darkness',\n",
       " 'darted',\n",
       " 'darting',\n",
       " 'dashed',\n",
       " 'dashing',\n",
       " 'daylight',\n",
       " 'deadly',\n",
       " 'decent',\n",
       " 'declare',\n",
       " 'declared',\n",
       " 'deemed',\n",
       " 'deeper',\n",
       " 'deepest',\n",
       " 'deeply',\n",
       " 'degree',\n",
       " 'deliberately',\n",
       " 'delicacy',\n",
       " 'delicate',\n",
       " 'delight',\n",
       " 'demanded',\n",
       " 'departed',\n",
       " 'depths',\n",
       " 'derive',\n",
       " 'derived',\n",
       " 'descend',\n",
       " 'descending',\n",
       " 'described',\n",
       " 'descried',\n",
       " 'description',\n",
       " 'desert',\n",
       " 'desire',\n",
       " 'desired',\n",
       " 'despair',\n",
       " 'desperate',\n",
       " 'destined',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'detached',\n",
       " 'determined',\n",
       " 'devilish',\n",
       " 'devils',\n",
       " 'dexterous',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dignity',\n",
       " 'diligently',\n",
       " 'diminished',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'direction',\n",
       " 'directions',\n",
       " 'directly',\n",
       " 'direful',\n",
       " 'disappeared',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discovery',\n",
       " 'dismal',\n",
       " 'distance',\n",
       " 'distant',\n",
       " 'distinct',\n",
       " 'distinctly',\n",
       " 'distinguished',\n",
       " 'divided',\n",
       " 'dividing',\n",
       " 'divine',\n",
       " 'dollars',\n",
       " 'domestic',\n",
       " 'double',\n",
       " 'doubloon',\n",
       " 'doubloons',\n",
       " 'doubtless',\n",
       " 'downward',\n",
       " 'downwards',\n",
       " 'dragged',\n",
       " 'dragging',\n",
       " 'drawers',\n",
       " 'drawing',\n",
       " 'dreadful',\n",
       " 'dreaming',\n",
       " 'dreams',\n",
       " 'dreary',\n",
       " 'dressed',\n",
       " 'dripping',\n",
       " 'driven',\n",
       " 'driving',\n",
       " 'drooping',\n",
       " 'dropped',\n",
       " 'dropping',\n",
       " 'drowned',\n",
       " 'drugged',\n",
       " 'dumplings',\n",
       " 'during',\n",
       " 'eagerly',\n",
       " 'eagerness',\n",
       " 'earnest',\n",
       " 'earnestly',\n",
       " 'earthly',\n",
       " 'easily',\n",
       " 'eating',\n",
       " 'effect',\n",
       " 'eighteen',\n",
       " 'either',\n",
       " 'elastic',\n",
       " 'element',\n",
       " 'elements',\n",
       " 'elephant',\n",
       " 'elephants',\n",
       " 'elevated',\n",
       " 'elsewhere',\n",
       " 'embalmed',\n",
       " 'emotions',\n",
       " 'employed',\n",
       " 'enchanted',\n",
       " 'encounter',\n",
       " 'encountered',\n",
       " 'encountering',\n",
       " 'endless',\n",
       " 'endure',\n",
       " 'energy',\n",
       " 'engaged',\n",
       " 'engravings',\n",
       " 'enormous',\n",
       " 'enough',\n",
       " 'enraged',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entitled',\n",
       " 'entrance',\n",
       " 'equally',\n",
       " 'escape',\n",
       " 'escaped',\n",
       " 'especially',\n",
       " 'eternal',\n",
       " 'eternally',\n",
       " 'evening',\n",
       " 'events',\n",
       " 'eventually',\n",
       " 'everlasting',\n",
       " 'everybody',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'evinced',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'exasperated',\n",
       " 'exceed',\n",
       " 'exceeding',\n",
       " 'exceedingly',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'excitement',\n",
       " 'exclaimed',\n",
       " 'existence',\n",
       " 'expand',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'explain',\n",
       " 'express',\n",
       " 'expression',\n",
       " 'extending',\n",
       " 'external',\n",
       " 'extraordinary',\n",
       " 'extreme',\n",
       " 'extremity',\n",
       " 'eyeing',\n",
       " 'fairly',\n",
       " 'faithful',\n",
       " 'falling',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fancied',\n",
       " 'fashion',\n",
       " 'fastened',\n",
       " 'fatality',\n",
       " 'father',\n",
       " 'fathoms',\n",
       " 'fearful',\n",
       " 'fearless',\n",
       " 'features',\n",
       " 'feeding',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'fellow',\n",
       " 'fellows',\n",
       " 'fibres',\n",
       " 'fields',\n",
       " 'fierce',\n",
       " 'fifteen',\n",
       " 'figure',\n",
       " 'figures',\n",
       " 'filled',\n",
       " 'finally',\n",
       " 'finding',\n",
       " 'finest',\n",
       " 'finger',\n",
       " 'fingers',\n",
       " 'firmly',\n",
       " 'fisherman',\n",
       " 'fishermen',\n",
       " 'fishery',\n",
       " 'fitted',\n",
       " 'flames',\n",
       " 'flanks',\n",
       " 'flight',\n",
       " 'flinging',\n",
       " 'flitting',\n",
       " 'floated',\n",
       " 'floating',\n",
       " 'floats',\n",
       " 'flukes',\n",
       " 'flying',\n",
       " 'folded',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'foolish',\n",
       " 'forced',\n",
       " 'forecastle',\n",
       " 'forehead',\n",
       " 'foreign',\n",
       " 'foremost',\n",
       " 'forged',\n",
       " 'forget',\n",
       " 'forgotten',\n",
       " 'forked',\n",
       " 'formed',\n",
       " 'former',\n",
       " 'forming',\n",
       " 'forward',\n",
       " 'fountain',\n",
       " 'fourth',\n",
       " 'fragrant',\n",
       " 'frantic',\n",
       " 'freely',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'fright',\n",
       " 'frightened',\n",
       " 'frozen',\n",
       " 'furious',\n",
       " 'furiously',\n",
       " 'furnish',\n",
       " 'furnished',\n",
       " 'further',\n",
       " 'future',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'gathered',\n",
       " 'gazing',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generations',\n",
       " 'gentle',\n",
       " 'gentleman',\n",
       " 'gentlemen',\n",
       " 'gently',\n",
       " 'getting',\n",
       " 'ghosts',\n",
       " 'gigantic',\n",
       " 'ginger',\n",
       " 'giving',\n",
       " 'glance',\n",
       " 'glanced',\n",
       " 'glances',\n",
       " 'glancing',\n",
       " 'glasses',\n",
       " 'glided',\n",
       " 'gliding',\n",
       " 'glimpse',\n",
       " 'glistening',\n",
       " 'glittering',\n",
       " 'golden',\n",
       " 'gradually',\n",
       " 'grandeur',\n",
       " 'grasped',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'greatly',\n",
       " 'grinning',\n",
       " 'ground',\n",
       " 'grounds',\n",
       " 'growing',\n",
       " 'gunwale',\n",
       " 'gunwales',\n",
       " 'hailed',\n",
       " 'hailing',\n",
       " 'hammer',\n",
       " 'hammered',\n",
       " 'hammers',\n",
       " 'hammock',\n",
       " 'handful',\n",
       " 'handle',\n",
       " 'handspikes',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'harbor',\n",
       " 'hardly',\n",
       " 'harmless',\n",
       " 'harpoon',\n",
       " 'harpooned',\n",
       " 'harpooneer',\n",
       " 'harpooneers',\n",
       " 'harpoons',\n",
       " 'hatches',\n",
       " 'hatchway',\n",
       " 'hauled',\n",
       " 'having',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'headlong',\n",
       " 'headsman',\n",
       " 'health',\n",
       " 'hearing',\n",
       " 'hearse',\n",
       " 'hearts',\n",
       " 'hearty',\n",
       " 'heathenish',\n",
       " 'heaved',\n",
       " 'heaven',\n",
       " 'heavenly',\n",
       " 'heavens',\n",
       " 'heavily',\n",
       " 'heaving',\n",
       " 'heeded',\n",
       " 'heedful',\n",
       " 'height',\n",
       " 'heightened',\n",
       " 'helmsman',\n",
       " 'helped',\n",
       " 'hempen',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'hereditary',\n",
       " 'herself',\n",
       " 'hidden',\n",
       " 'hideous',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'highly',\n",
       " 'himself',\n",
       " 'hinted',\n",
       " 'historical',\n",
       " 'history',\n",
       " 'hither',\n",
       " 'hitherto',\n",
       " 'hoisted',\n",
       " 'hoisting',\n",
       " 'holding',\n",
       " 'hollow',\n",
       " 'homage',\n",
       " 'honest',\n",
       " 'honour',\n",
       " 'honourable',\n",
       " 'hooded',\n",
       " 'hopeless',\n",
       " 'horizon',\n",
       " 'horizontal',\n",
       " 'horrible',\n",
       " 'horror',\n",
       " 'horses',\n",
       " 'houses',\n",
       " 'hovered',\n",
       " 'hovering',\n",
       " 'however',\n",
       " 'howling',\n",
       " 'hundred',\n",
       " 'hundreds',\n",
       " 'hunted',\n",
       " 'hunter',\n",
       " 'hunters',\n",
       " 'hunting',\n",
       " 'hurled',\n",
       " 'hurried',\n",
       " 'identical',\n",
       " 'ignorance',\n",
       " 'ignorant',\n",
       " 'immediate',\n",
       " 'immediately',\n",
       " 'immemorial',\n",
       " 'immense',\n",
       " 'immortal',\n",
       " 'imperial',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressions',\n",
       " 'inasmuch',\n",
       " 'inches',\n",
       " 'incidentally',\n",
       " 'inclined',\n",
       " 'included',\n",
       " 'including',\n",
       " 'increased',\n",
       " 'incredible',\n",
       " 'indeed',\n",
       " 'independent',\n",
       " 'indifference',\n",
       " 'indifferent',\n",
       " 'indirectly',\n",
       " 'indispensable',\n",
       " 'individual',\n",
       " 'indolent',\n",
       " 'inexplicable',\n",
       " 'infallibly',\n",
       " 'inferior',\n",
       " 'infernal',\n",
       " 'infidel',\n",
       " 'infinite',\n",
       " 'influence',\n",
       " 'influences',\n",
       " 'inland',\n",
       " 'innermost',\n",
       " 'insanity',\n",
       " 'inscrutable',\n",
       " 'inserted',\n",
       " 'inside',\n",
       " 'instance',\n",
       " 'instances',\n",
       " 'instant',\n",
       " 'instantly',\n",
       " 'instead',\n",
       " 'instinct',\n",
       " 'insult',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'intended',\n",
       " 'intense',\n",
       " 'intensity',\n",
       " 'intent',\n",
       " 'intention',\n",
       " 'intently',\n",
       " 'interest',\n",
       " 'interesting',\n",
       " 'interior',\n",
       " 'interval',\n",
       " 'intervals',\n",
       " 'intolerable',\n",
       " 'introduced',\n",
       " 'invariably',\n",
       " 'invest',\n",
       " 'invested',\n",
       " 'invisible',\n",
       " 'involuntarily',\n",
       " 'involve',\n",
       " 'involved',\n",
       " 'irregular',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    dist=FreqDist(text1)\n",
    "    list1=[w for w in dist.keys() if len(w)>5 and dist[w]>150]\n",
    "    \n",
    "    return sorted(list1)\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    dist=FreqDist(text1)\n",
    "    '''\n",
    "    for i in dist.keys():\n",
    "        dist[i]=len(i)\n",
    "    \n",
    "    dist1=pd.Series(dist)\n",
    "    dist1.sort_values(ascending=False, inplace=True)\n",
    "    return (dist1.index[0], dist1[0])\n",
    "    '''\n",
    "    vol=dist.keys()\n",
    "    import operator\n",
    "    return sorted([(i, len(i)) for i in vol], reverse=True, key=operator.itemgetter(1))[0]\n",
    "    \n",
    "   \n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "def answer_six():\n",
    "    dist=FreqDist(text1)\n",
    "    list1=[(v, w) for w , v in dist.items() if v>2000 and w.isalpha()]\n",
    "    return sorted(list1, reverse=True, key=operator.itemgetter(0))\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    \n",
    "    sents=nltk.sent_tokenize(moby_raw)\n",
    "    \n",
    "    return np.mean([len(nltk.word_tokenize(i)) for i in sents])\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 32730), ('IN', 28657), ('DT', 25867), (',', 19204), ('JJ', 17620)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eight():\n",
    "    \n",
    "    import operator\n",
    "    \n",
    "    list1=nltk.pos_tag(text1)\n",
    "    list2=[]\n",
    "    for k in list1:\n",
    "        list2.append(k[1])\n",
    "    list3=FreqDist(list2)\n",
    "    \n",
    "    return sorted([(k,v) for k, v in list3.items()], reverse=True, key=operator.itemgetter(1))[:5]\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell[0]==entry[0] and len(spell) > 2]\n",
    "        distance_list = [(spell, nltk.jaccard_distance(set(nltk.ngrams(entry, n=3)), set(nltk.ngrams(spell, n=3)))) for spell in spell_list]\n",
    "\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    \n",
    "    return result # Your answer here\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell.startswith(entry[0]) and len(spell) > 2]\n",
    "        distance_list = [(spell, nltk.jaccard_distance(set(nltk.ngrams(entry, n=4)), set(nltk.ngrams(spell, n=4)))) for spell in spell_list]\n",
    "\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    \n",
    "    return result\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    result = []\n",
    "    import operator\n",
    "    for entry in entries:\n",
    "        spell_list = [spell for spell in correct_spellings if spell.startswith(entry[0]) and len(spell) > 2]\n",
    "        distance_list = [(spell, nltk.edit_distance(entry, spell, transpositions=True)) for spell in spell_list]\n",
    "\n",
    "        result.append(sorted(distance_list, key=operator.itemgetter(1))[0][0])\n",
    "    \n",
    "    \n",
    "    return result# Your answer here \n",
    "    \n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
